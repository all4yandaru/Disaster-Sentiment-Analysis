---
title: "Bencana"
author: "Allyandaru"
date: "1/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup package yang dibutuhkan
```{r}
library(shiny) # pembuatan web
library(here) # akses lokasi
library(vroom) # akses csv
library(dplyr) # manupulasi data glimpse, summaries, group, dll
library(ggplot2) # plotting 
library(plotly) # plotting
library(topicmodels) # pembuatan LDA
library(tidyverse)
library(tidytext) # Untuk Text Mining dan Preprocessing

bencana_raw <- vroom(here("data-raw", "tweets.csv"))
glimpse(bencana_raw)
bencana <- bencana_raw %>% select(-location, -target) %>% filter(keyword == "flood" | keyword == "earthquake" | keyword == "volcano")
bencana
```

## penentuan testing dan training
```{r}

# cleaning
bencana$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", bencana$text)
bencana$text <- gsub("@\\w+", " ", bencana$text)
bencana$text <- gsub("#\\w+", " ", bencana$text)
bencana$text <- gsub("https://t.co/\\w+", " ", bencana$text)
bencana$text <- gsub('[[:punct:]]', " ", bencana$text)
bencana$text <- gsub('[[:cntrl:]]', " ", bencana$text)
bencana$text <- gsub('\\d+', "", bencana$text)
bencana$text <- gsub("[ \t]{2,}", " ", bencana$text)
bencana$text <- gsub("^\\s+|\\s+$", "", bencana$text)
bencana$text <- tolower(bencana$text)

# menghilangkan stopwords
bencana <- bencana %>%
  group_by(id, keyword) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  summarize(text = str_c(word, collapse = " ")) %>%
  ungroup()
```
# Training testing
```{r}
# penentuan training dan sample
dt <- sort(sample(nrow(bencana), nrow(bencana)*.7)) # 70 persen utk training
train <- bencana[dt,]
testing <- bencana[-dt,]
```

## proses prediksi
```{r}
glimpse(bencana)
#test_akurasi <- data.frame(k = integer(), akurasi = numeric())
#for (key in seq(3, 10, 2)) { # increment 3 - 10 sebanyak 2
  
  hasil_prediksi <- data.frame(id = integer(), keyword = character())

  for (i in 1:nrow(testing)) {
    cat(sprintf("Proses: (%d / %d)\n", i, nrow(testing)))
    
    # mengambil data yang akan diprediksi kemudian digabungkan ke training
    predict <- testing[i,]
    data_tidy <- train %>% rbind(predict)
    
    # membuat tf idf
    data_tfidf <- data_tidy %>% 
      unnest_tokens(word, text) %>%
      count(id, word, sort = TRUE) %>%
      bind_tf_idf(word, id, n)
    
    # mengambil kata2 yang akan diprediksi, kemudian mengalikan data predict dan data training untuk dimasukkan ke rumus cosine
    predict_w <- data_tfidf %>% filter(id == predict$id)
    
    bobot_training <- data.frame(id = integer(), total = numeric())
    
    # pembobotan, penjumlahan bobot
    for (j in 1:nrow(train)) {
      temp_train <- data_tfidf %>%
        filter(id == train$id[j])
      
      data_join <- predict_w %>%
        inner_join(temp_train, by = "word") %>%
        mutate(hasil_kali = tf_idf.x * tf_idf.y)
      
      bobot_training <- bobot_training %>%
        rbind(data.frame(id = train$id[j], total = sum(data_join$hasil_kali)))
    }
    
    # menentukan panjang data
    panjang_training <- data.frame(id = integer(), akar = numeric())
    
    for (j in 1:nrow(data_tidy)) {
      temp_train <- data_tfidf %>%
        filter(id == data_tidy$id[j])
      
      kuadrat_temp <- temp_train$tf_idf^2
      akar_temp <- sqrt(sum(kuadrat_temp))
      
      panjang_training <- panjang_training %>%
        rbind(data.frame(id = data_tidy$id[j], akar = akar_temp))
    }
    
    # cosine similarity
    predict_panjang <- panjang_training %>% filter(id == predict$id)
    
    cosine <- data.frame(id = integer(), hasil_cosine = numeric())
    
    for (j in 1:nrow(train)) {
      cosine_temp <- bobot_training$total[j] / (predict_panjang$akar * panjang_training$akar[j])
      cosine <- cosine %>%
        rbind(data.frame(id = train$id[j], hasil_cosine = cosine_temp))
    }
    # sorting hasil cosine
    cosine <- cosine %>% arrange(desc(hasil_cosine))
    
    
    # proses knn
    k <- 7 # diusahakan ganjil, 7 yang paling tinggi
    
    predict_knn <- cosine %>%
      inner_join(train, by = "id") %>%
      select(id, hasil_cosine, keyword, text) %>%
      head(k)
    
    sentiment_predict <- predict_knn %>% count(keyword)
    sentiment_predict <- sentiment_predict$keyword[which.max(sentiment_predict$n)]
    
    hasil_prediksi <- hasil_prediksi %>%
      rbind(data.frame(id = predict$id, keyword = sentiment_predict))
  }
  
  hasil_prediksi %>% arrange(desc(id))


# Testing akurasi

  compare_predict <- testing
  compare_predict <- compare_predict %>% 
    inner_join(hasil_prediksi, by = "id") %>%
    mutate(akurasi_poin = ifelse(keyword.x == keyword.y, 1, 0))
  
  compare_predict %>% arrange(desc(id))
  
  compare_predict %>% group_by(keyword.x) %>% count()
  
  #akurasi <- (compare_predict %>%
  #  filter(akurasi_poin == 1) %>%
  #  count())$n / (compare_predict %>%
  #  count())$n
  #akurasi
  
  #test_akurasi <- test_akurasi %>% rbind(data.frame(k = key, akurasi = akurasi))
  
  test_akurasi
#}
#test_akurasi
```