cosine <- cosine %>%
rbind(data.frame(id = train$id[j], hasil_cosine = cosine_temp))
}
# sorting hasil cosine
cosine <- cosine %>% arrange(desc(hasil_cosine))
# proses knn
k <- 7 # diusahakan ganjil, 7 yang paling tinggi
# dicari 7 data terdekat
predict_knn <- cosine %>%
inner_join(train, by = "id") %>%
select(id, hasil_cosine, keyword, text) %>%
head(k)
sentiment_predict <- predict_knn %>% count(keyword)
sentiment_predict <- sentiment_predict$keyword[which.max(sentiment_predict$n)]
hasil_prediksi <- hasil_prediksi %>%
rbind(data.frame(id = predict$id, keyword = sentiment_predict))
}
hasil_prediksi %>% arrange(desc(id))
# Testing akurasi
#compare_predict <- testing
#compare_predict <- compare_predict %>%
#  inner_join(hasil_prediksi, by = "id") %>%
#  mutate(akurasi_poin = ifelse(keyword.x == keyword.y, 1, 0))
#compare_predict %>% arrange(desc(id))
#compare_predict %>% group_by(keyword.x) %>% count()
#akurasi <- (compare_predict %>%
#  filter(akurasi_poin == 1) %>%
#  count())$n / (compare_predict %>%
#  count())$n
#akurasi
#test_akurasi <- test_akurasi %>% rbind(data.frame(k = key, akurasi = akurasi))
test_akurasi
#}
#test_akurasi
# penentuan training dan sample
train <- bencana
dt <- sort(sample(nrow(bencana_scraping), nrow(bencana_scraping)*.1)) # 10 persen data scraping
dt <- bencana_scraping[dt,]
view(dt)
testing <- data.frame(id = integer(), keyword = character(), text = character())
testing <- testing%>% rbind(data.frame(dt)) %>% mutate(keyword = NA)
view(testing)
#dt <- sort(sample(nrow(bencana), nrow(bencana)*.7)) # 70 persen utk training
#train <- bencana[dt,]
#testing <- bencana[-dt,]
glimpse(train)
glimpse(testing)
glimpse(bencana)
#test_akurasi <- data.frame(k = integer(), akurasi = numeric())
#for (key in seq(3, 10, 2)) { # increment 3 - 10 sebanyak 2
hasil_prediksi <- data.frame(id = integer(), keyword = character())
for (i in 1:nrow(testing)) {
cat(sprintf("Proses: (%d / %d)\n", i, nrow(testing)))
# mengambil data yang akan diprediksi kemudian digabungkan ke training
predict <- testing[i,]
data_tidy <- train %>% rbind(predict)
# membuat tf idf
data_tfidf <- data_tidy %>%
unnest_tokens(word, text) %>%
count(id, word, sort = TRUE) %>%
bind_tf_idf(word, id, n)
# mengambil kata2 yang akan diprediksi, kemudian mengalikan data predict dan data training untuk dimasukkan ke rumus cosine
predict_w <- data_tfidf %>% filter(id == predict$id)
bobot_training <- data.frame(id = integer(), total = numeric())
# pembobotan, penjumlahan bobot
for (j in 1:nrow(train)) {
temp_train <- data_tfidf %>%
filter(id == train$id[j])
data_join <- predict_w %>%
inner_join(temp_train, by = "word") %>%
mutate(hasil_kali = tf_idf.x * tf_idf.y)
bobot_training <- bobot_training %>%
rbind(data.frame(id = train$id[j], total = sum(data_join$hasil_kali)))
}
# menentukan panjang data
panjang_training <- data.frame(id = integer(), akar = numeric())
for (j in 1:nrow(data_tidy)) {
temp_train <- data_tfidf %>%
filter(id == data_tidy$id[j])
kuadrat_temp <- temp_train$tf_idf^2
akar_temp <- sqrt(sum(kuadrat_temp))
panjang_training <- panjang_training %>%
rbind(data.frame(id = data_tidy$id[j], akar = akar_temp))
}
# cosine similarity
predict_panjang <- panjang_training %>% filter(id == predict$id)
cosine <- data.frame(id = integer(), hasil_cosine = numeric())
for (j in 1:nrow(train)) {
cosine_temp <- bobot_training$total[j] / (predict_panjang$akar * panjang_training$akar[j])
cosine <- cosine %>%
rbind(data.frame(id = train$id[j], hasil_cosine = cosine_temp))
}
# sorting hasil cosine
cosine <- cosine %>% arrange(desc(hasil_cosine))
# proses knn
k <- 7 # diusahakan ganjil, 7 yang paling tinggi
# dicari 7 data terdekat
predict_knn <- cosine %>%
inner_join(train, by = "id") %>%
select(id, hasil_cosine, keyword, text) %>%
head(k)
sentiment_predict <- predict_knn %>% count(keyword)
sentiment_predict <- sentiment_predict$keyword[which.max(sentiment_predict$n)]
hasil_prediksi <- hasil_prediksi %>%
rbind(data.frame(id = predict$id, keyword = sentiment_predict))
}
hasil_prediksi %>% arrange(desc(id))
# Testing akurasi
#compare_predict <- testing
#compare_predict <- compare_predict %>%
#  inner_join(hasil_prediksi, by = "id") %>%
#  mutate(akurasi_poin = ifelse(keyword.x == keyword.y, 1, 0))
#compare_predict %>% arrange(desc(id))
#compare_predict %>% group_by(keyword.x) %>% count()
#akurasi <- (compare_predict %>%
#  filter(akurasi_poin == 1) %>%
#  count())$n / (compare_predict %>%
#  count())$n
#akurasi
#test_akurasi <- test_akurasi %>% rbind(data.frame(k = key, akurasi = akurasi))
test_akurasi
#}
#test_akurasi
hasil_prediksi %>% arrange(desc(id))
predict_knn
glimpse(bencana)
#test_akurasi <- data.frame(k = integer(), akurasi = numeric())
#for (key in seq(3, 10, 2)) { # increment 3 - 10 sebanyak 2
hasil_prediksi <- data.frame(id = integer(), keyword = character(), text = character())
for (i in 1:nrow(testing)) {
cat(sprintf("Proses: (%d / %d)\n", i, nrow(testing)))
# mengambil data yang akan diprediksi kemudian digabungkan ke training
predict <- testing[i,]
data_tidy <- train %>% rbind(predict)
# membuat tf idf
data_tfidf <- data_tidy %>%
unnest_tokens(word, text) %>%
count(id, word, sort = TRUE) %>%
bind_tf_idf(word, id, n)
# mengambil kata2 yang akan diprediksi, kemudian mengalikan data predict dan data training untuk dimasukkan ke rumus cosine
predict_w <- data_tfidf %>% filter(id == predict$id)
bobot_training <- data.frame(id = integer(), total = numeric())
# pembobotan, penjumlahan bobot
for (j in 1:nrow(train)) {
temp_train <- data_tfidf %>%
filter(id == train$id[j])
data_join <- predict_w %>%
inner_join(temp_train, by = "word") %>%
mutate(hasil_kali = tf_idf.x * tf_idf.y)
bobot_training <- bobot_training %>%
rbind(data.frame(id = train$id[j], total = sum(data_join$hasil_kali)))
}
# menentukan panjang data
panjang_training <- data.frame(id = integer(), akar = numeric())
for (j in 1:nrow(data_tidy)) {
temp_train <- data_tfidf %>%
filter(id == data_tidy$id[j])
kuadrat_temp <- temp_train$tf_idf^2
akar_temp <- sqrt(sum(kuadrat_temp))
panjang_training <- panjang_training %>%
rbind(data.frame(id = data_tidy$id[j], akar = akar_temp))
}
# cosine similarity
predict_panjang <- panjang_training %>% filter(id == predict$id)
cosine <- data.frame(id = integer(), hasil_cosine = numeric())
for (j in 1:nrow(train)) {
cosine_temp <- bobot_training$total[j] / (predict_panjang$akar * panjang_training$akar[j])
cosine <- cosine %>%
rbind(data.frame(id = train$id[j], hasil_cosine = cosine_temp))
}
# sorting hasil cosine
cosine <- cosine %>% arrange(desc(hasil_cosine))
# proses knn
k <- 7 # diusahakan ganjil, 7 yang paling tinggi
# dicari 7 data terdekat
predict_knn <- cosine %>%
inner_join(train, by = "id") %>%
select(id, hasil_cosine, keyword, text) %>%
head(k)
sentiment_predict <- predict_knn %>% count(keyword)
sentiment_predict <- sentiment_predict$keyword[which.max(sentiment_predict$n)]
hasil_prediksi <- hasil_prediksi %>%
rbind(data.frame(id = predict$id, keyword = sentiment_predict))
}
hasil_prediksi %>% mutate(text = testing$text) arrange(desc(id))
hasil_prediksi %>% mutate(text = testing$text) %>% arrange(desc(id))
view(hasil_prediksi)
view(testing)
data_akhir <- hasil_prediksi %>% left_join(testing, by = "id")
view(data_akhir)
data_akhir <- hasil_prediksi %>% left_join(testing, by = "id") %>% select(-keyword.y)
view(data_akhir)
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y) %>%
rename("keyword.x" = "keyword")
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y)
view(data_akhir)
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y) %>%
rename(c("keyword.x" = "keyword"))
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y)
view(data_akhir)
test_akurasi
test_akurasi
# penentuan training dan sample
#train <- bencana
#dt <- sort(sample(nrow(bencana_scraping), nrow(bencana_scraping)*.1)) # 10 persen data scraping
#dt <- bencana_scraping[dt,]
#view(dt)
#testing <- data.frame(id = integer(), keyword = character(), text = character())
#testing <- testing%>% rbind(data.frame(dt)) %>% mutate(keyword = NA)
#view(testing)
dt <- sort(sample(nrow(bencana), nrow(bencana)*.7)) # 70 persen utk training
train <- bencana[dt,]
testing <- bencana[-dt,]
glimpse(train)
glimpse(testing)
glimpse(bencana)
#test_akurasi <- data.frame(k = integer(), akurasi = numeric())
#for (key in seq(3, 10, 2)) { # increment 3 - 10 sebanyak 2
hasil_prediksi <- data.frame(id = integer(), keyword = character(), text = character())
for (i in 1:nrow(testing)) {
cat(sprintf("Proses: (%d / %d)\n", i, nrow(testing)))
# mengambil data yang akan diprediksi kemudian digabungkan ke training
predict <- testing[i,]
data_tidy <- train %>% rbind(predict)
# membuat tf idf
data_tfidf <- data_tidy %>%
unnest_tokens(word, text) %>%
count(id, word, sort = TRUE) %>%
bind_tf_idf(word, id, n)
# mengambil kata2 yang akan diprediksi, kemudian mengalikan data predict dan data training untuk dimasukkan ke rumus cosine
predict_w <- data_tfidf %>% filter(id == predict$id)
bobot_training <- data.frame(id = integer(), total = numeric())
# pembobotan, penjumlahan bobot
for (j in 1:nrow(train)) {
temp_train <- data_tfidf %>%
filter(id == train$id[j])
data_join <- predict_w %>%
inner_join(temp_train, by = "word") %>%
mutate(hasil_kali = tf_idf.x * tf_idf.y)
bobot_training <- bobot_training %>%
rbind(data.frame(id = train$id[j], total = sum(data_join$hasil_kali)))
}
# menentukan panjang data
panjang_training <- data.frame(id = integer(), akar = numeric())
for (j in 1:nrow(data_tidy)) {
temp_train <- data_tfidf %>%
filter(id == data_tidy$id[j])
kuadrat_temp <- temp_train$tf_idf^2
akar_temp <- sqrt(sum(kuadrat_temp))
panjang_training <- panjang_training %>%
rbind(data.frame(id = data_tidy$id[j], akar = akar_temp))
}
# cosine similarity
predict_panjang <- panjang_training %>% filter(id == predict$id)
cosine <- data.frame(id = integer(), hasil_cosine = numeric())
for (j in 1:nrow(train)) {
cosine_temp <- bobot_training$total[j] / (predict_panjang$akar * panjang_training$akar[j])
cosine <- cosine %>%
rbind(data.frame(id = train$id[j], hasil_cosine = cosine_temp))
}
# sorting hasil cosine
cosine <- cosine %>% arrange(desc(hasil_cosine))
# proses knn
k <- 7 # diusahakan ganjil, 7 yang paling tinggi
# dicari 7 data terdekat
predict_knn <- cosine %>%
inner_join(train, by = "id") %>%
select(id, hasil_cosine, keyword, text) %>%
head(k)
sentiment_predict <- predict_knn %>% count(keyword)
sentiment_predict <- sentiment_predict$keyword[which.max(sentiment_predict$n)]
hasil_prediksi <- hasil_prediksi %>%
rbind(data.frame(id = predict$id, keyword = sentiment_predict))
}
hasil_prediksi %>% mutate(text = testing$text) %>% arrange(desc(id))
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y)
view(data_akhir)
# Testing akurasi
#compare_predict <- testing
#compare_predict <- compare_predict %>%
#  inner_join(hasil_prediksi, by = "id") %>%
#  mutate(akurasi_poin = ifelse(keyword.x == keyword.y, 1, 0))
#compare_predict %>% arrange(desc(id))
#compare_predict %>% group_by(keyword.x) %>% count()
#akurasi <- (compare_predict %>%
#  filter(akurasi_poin == 1) %>%
#  count())$n / (compare_predict %>%
#  count())$n
#akurasi
#test_akurasi <- test_akurasi %>% rbind(data.frame(k = key, akurasi = akurasi))
test_akurasi
#}
#test_akurasi
# penentuan training dan sample
train <- bencana
# penentuan training dan sample
train <- bencana
dt <- sort(sample(nrow(bencana_scraping), nrow(bencana_scraping)*.1)) # 10 persen data scraping
dt <- bencana_scraping[dt,]
view(dt)
testing <- data.frame(id = integer(), keyword = character(), text = character())
testing <- testing%>% rbind(data.frame(dt)) %>% mutate(keyword = NA)
view(testing)
#dt <- sort(sample(nrow(bencana), nrow(bencana)*.7)) # 70 persen utk training
#train <- bencana[dt,]
#testing <- bencana[-dt,]
glimpse(train)
glimpse(testing)
data_akhir <- hasil_prediksi %>%
left_join(bencana_scraping, by = "id") %>%
select(-keyword.y)
View(bencana_scraping)
data_akhir <- hasil_prediksi %>%
left_join(bencana_raw_scraping, by = "id") %>%
select(-keyword.y)
data_akhir <- hasil_prediksi %>%
left_join(bencana_raw_scraping, by = "id")
view(data_akhir)
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y)
view(data_akhir)
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y)
view(data_akhir)
glimpse(bencana)
#test_akurasi <- data.frame(k = integer(), akurasi = numeric())
#for (key in seq(3, 10, 2)) { # increment 3 - 10 sebanyak 2
hasil_prediksi <- data.frame(id = integer(), keyword = character(), text = character())
for (i in 1:nrow(testing)) {
cat(sprintf("Proses: (%d / %d)\n", i, nrow(testing)))
# mengambil data yang akan diprediksi kemudian digabungkan ke training
predict <- testing[i,]
data_tidy <- train %>% rbind(predict)
# membuat tf idf
data_tfidf <- data_tidy %>%
unnest_tokens(word, text) %>%
count(id, word, sort = TRUE) %>%
bind_tf_idf(word, id, n)
# mengambil kata2 yang akan diprediksi, kemudian mengalikan data predict dan data training untuk dimasukkan ke rumus cosine
predict_w <- data_tfidf %>% filter(id == predict$id)
bobot_training <- data.frame(id = integer(), total = numeric())
# pembobotan, penjumlahan bobot
for (j in 1:nrow(train)) {
temp_train <- data_tfidf %>%
filter(id == train$id[j])
data_join <- predict_w %>%
inner_join(temp_train, by = "word") %>%
mutate(hasil_kali = tf_idf.x * tf_idf.y)
bobot_training <- bobot_training %>%
rbind(data.frame(id = train$id[j], total = sum(data_join$hasil_kali)))
}
# menentukan panjang data
panjang_training <- data.frame(id = integer(), akar = numeric())
for (j in 1:nrow(data_tidy)) {
temp_train <- data_tfidf %>%
filter(id == data_tidy$id[j])
kuadrat_temp <- temp_train$tf_idf^2
akar_temp <- sqrt(sum(kuadrat_temp))
panjang_training <- panjang_training %>%
rbind(data.frame(id = data_tidy$id[j], akar = akar_temp))
}
# cosine similarity
predict_panjang <- panjang_training %>% filter(id == predict$id)
cosine <- data.frame(id = integer(), hasil_cosine = numeric())
for (j in 1:nrow(train)) {
cosine_temp <- bobot_training$total[j] / (predict_panjang$akar * panjang_training$akar[j])
cosine <- cosine %>%
rbind(data.frame(id = train$id[j], hasil_cosine = cosine_temp))
}
# sorting hasil cosine
cosine <- cosine %>% arrange(desc(hasil_cosine))
# proses knn
k <- 7 # diusahakan ganjil, 7 yang paling tinggi
# dicari 7 data terdekat
predict_knn <- cosine %>%
inner_join(train, by = "id") %>%
select(id, hasil_cosine, keyword, text) %>%
head(k)
sentiment_predict <- predict_knn %>% count(keyword)
sentiment_predict <- sentiment_predict$keyword[which.max(sentiment_predict$n)]
hasil_prediksi <- hasil_prediksi %>%
rbind(data.frame(id = predict$id, keyword = sentiment_predict))
}
hasil_prediksi %>% mutate(text = testing$text) %>% arrange(desc(id))
# penentuan training dan sample
train <- bencana
dt <- sort(sample(nrow(bencana_scraping), nrow(bencana_scraping)*.1)) # 10 persen data scraping
dt <- bencana_scraping[dt,]
testing <- data.frame(id = integer(), keyword = character(), text = character())
testing <- testing%>% rbind(data.frame(dt)) %>% mutate(keyword = NA)
view(testing)
#dt <- sort(sample(nrow(bencana), nrow(bencana)*.7)) # 70 persen utk training
#train <- bencana[dt,]
#testing <- bencana[-dt,]
glimpse(train)
glimpse(testing)
# penentuan training dan sample
train <- bencana
dt <- sort(sample(nrow(bencana_scraping), nrow(bencana_scraping)*.1)) # 10 persen data scraping
dt <- bencana_scraping[dt,]
testing <- data.frame(id = integer(), keyword = character(), text = character())
testing <- testing%>% rbind(data.frame(dt)) %>% mutate(keyword = NA)
view(testing)
#dt <- sort(sample(nrow(bencana), nrow(bencana)*.7)) # 70 persen utk training
#train <- bencana[dt,]
#testing <- bencana[-dt,]
glimpse(train)
glimpse(testing)
view(testing)
glimpse(bencana)
#test_akurasi <- data.frame(k = integer(), akurasi = numeric())
#for (key in seq(3, 10, 2)) { # increment 3 - 10 sebanyak 2
hasil_prediksi <- data.frame(id = integer(), keyword = character(), text = character())
for (i in 1:nrow(testing)) {
cat(sprintf("Proses: (%d / %d)\n", i, nrow(testing)))
# mengambil data yang akan diprediksi kemudian digabungkan ke training
predict <- testing[i,]
data_tidy <- train %>% rbind(predict)
# membuat tf idf
data_tfidf <- data_tidy %>%
unnest_tokens(word, text) %>%
count(id, word, sort = TRUE) %>%
bind_tf_idf(word, id, n)
# mengambil kata2 yang akan diprediksi, kemudian mengalikan data predict dan data training untuk dimasukkan ke rumus cosine
predict_w <- data_tfidf %>% filter(id == predict$id)
bobot_training <- data.frame(id = integer(), total = numeric())
# pembobotan, penjumlahan bobot
for (j in 1:nrow(train)) {
temp_train <- data_tfidf %>%
filter(id == train$id[j])
data_join <- predict_w %>%
inner_join(temp_train, by = "word") %>%
mutate(hasil_kali = tf_idf.x * tf_idf.y)
bobot_training <- bobot_training %>%
rbind(data.frame(id = train$id[j], total = sum(data_join$hasil_kali)))
}
# menentukan panjang data
panjang_training <- data.frame(id = integer(), akar = numeric())
for (j in 1:nrow(data_tidy)) {
temp_train <- data_tfidf %>%
filter(id == data_tidy$id[j])
kuadrat_temp <- temp_train$tf_idf^2
akar_temp <- sqrt(sum(kuadrat_temp))
panjang_training <- panjang_training %>%
rbind(data.frame(id = data_tidy$id[j], akar = akar_temp))
}
# cosine similarity
predict_panjang <- panjang_training %>% filter(id == predict$id)
cosine <- data.frame(id = integer(), hasil_cosine = numeric())
for (j in 1:nrow(train)) {
cosine_temp <- bobot_training$total[j] / (predict_panjang$akar * panjang_training$akar[j])
cosine <- cosine %>%
rbind(data.frame(id = train$id[j], hasil_cosine = cosine_temp))
}
# sorting hasil cosine
cosine <- cosine %>% arrange(desc(hasil_cosine))
# proses knn
k <- 7 # diusahakan ganjil, 7 yang paling tinggi
# dicari 7 data terdekat
predict_knn <- cosine %>%
inner_join(train, by = "id") %>%
select(id, hasil_cosine, keyword, text) %>%
head(k)
sentiment_predict <- predict_knn %>% count(keyword)
sentiment_predict <- sentiment_predict$keyword[which.max(sentiment_predict$n)]
hasil_prediksi <- hasil_prediksi %>%
rbind(data.frame(id = predict$id, keyword = sentiment_predict))
}
hasil_prediksi %>% mutate(text = testing$text) %>% arrange(desc(id))
data_akhir <- hasil_prediksi %>%
left_join(testing, by = "id") %>%
select(-keyword.y)
view(data_akhir)
# Testing akurasi
#compare_predict <- testing
#compare_predict <- compare_predict %>%
#  inner_join(hasil_prediksi, by = "id") %>%
#  mutate(akurasi_poin = ifelse(keyword.x == keyword.y, 1, 0))
#compare_predict %>% arrange(desc(id))
#compare_predict %>% group_by(keyword.x) %>% count()
#akurasi <- (compare_predict %>%
#  filter(akurasi_poin == 1) %>%
#  count())$n / (compare_predict %>%
#  count())$n
#akurasi
#test_akurasi <- test_akurasi %>% rbind(data.frame(k = key, akurasi = akurasi))
test_akurasi
#}
#test_akurasi
text_raw <- bencana_raw_scraping %>% select(id, text)
data_akhir <- hasil_prediksi %>%
left_join(text_raw, by = "id") %>%
select(-keyword.y)
data_akhir <- hasil_prediksi %>%
left_join(text_raw, by = "id")
view(data_akhir)
View(bencana_scraping)
View(bencana_raw_scraping)
View(bencanaraw)
View(bencana_scraping)
